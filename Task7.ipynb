{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dcec2-3c3f-49a1-9c15-cb7ecd2b9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7 \n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8cacd9-5b70-472e-be04-cfaef50d756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3016cff-ab14-4ba9-9c3c-f1008dc8a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toknisation & Standerdisation\n",
    "def tokenise_words(input):\n",
    "    input = input.lower()\n",
    "    tokeniser = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokeniser.tokenise(input)\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "processed_inputs = tokenise_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4dd24-e74e-4205-9adb-aaec6f86c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char to num\n",
    "char = sorted(list(set(processede_input)))\n",
    "ch2num = dict(c,i) for i, c in enumerate(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe25fb-c908-456e-a293-b8a0ae372b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking ch2num\n",
    "input_len = len(processed_input)\n",
    "vocab_len = len(char)\n",
    "print(\"characters\", input_len)\n",
    "print(\"vocab\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d08b2b-6152-4dfa-a977-4bce4cfe6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq len\n",
    "seq_len = 100\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc3c3f-6c59-4b50-a5bf-554af7fdad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping in seq\n",
    "for i in range(0, input_len - seq_len, 1):\n",
    "    in_ = processed_input(i:i + seq_len)\n",
    "    out = processed_input(i + seq_len)\n",
    "    x.append([ch2num(char) for char in in_])\n",
    "    y.append(ch2num[out])\n",
    "\n",
    "n_patterns = len(x)\n",
    "print(\"Tortal patterns : \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462feca-b32d-4c35-9321-0111f269a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input seq to np array\n",
    "X = np.reshape(x, (n_patterns, seq_len, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047abe8-df1c-4216-b0a5-3cfe14209e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "Y = np_utils.to_catagorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa58fc-1188-4ffa-81d2-4ba97de32c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616190f-be2f-4a35-b5e8-05f5c0dfe02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='catagorical_crossentropy', optimiser='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb958299-1976-471a-a639-073624383cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving weights\n",
    "filepath = \"\"\n",
    "chekpoint = ModdelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33807d6-19c7-466f-9c36-fa23d9ab4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and train model\n",
    "model.fit(X, Y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7e893-0cb3-4495-a9ec-8b889398f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the model \n",
    "filename = \"\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='catagorical_crossentropy', optimiser='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d969b97-7d66-4cc4-aac6-e2fb848858c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output back into chars\n",
    "num2ch = dict((i,c) for i, c in enumerate(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6490c7-cca9-43ef-bb98-cf0f5e4f2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sdeed to help generate\n",
    "start = np.random.randint(0, len(x) - 1)\n",
    "pattern = x[start]\n",
    "print(\"Random seed:\")\n",
    "print(\"\\\"\", ''.join([num2ch[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0ebdd-e1bb-4698-8ed7-9648da600cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate characters\n",
    "generated_text = []\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = num2ch[index]\n",
    "    generated_text.append(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994c18d-e806-49ea-96c4-8c0461ac4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output generated text\n",
    "print(\"Generated Text:\")\n",
    "print(''.join(generated_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
