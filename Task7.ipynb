{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1dcec2-3c3f-49a1-9c15-cb7ecd2b9290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\benja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Task 7 \n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8cacd9-5b70-472e-be04-cfaef50d756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"frankenstein.txt\", encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3016cff-ab14-4ba9-9c3c-f1008dc8a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toknisation & Standerdisation\n",
    "def tokenise_words(input):\n",
    "    input = input.lower()\n",
    "    # tokeniser = RegexpTokenizer(r'\\w+')\n",
    "    tokens = regexp_tokenize(input, r'\\w+')\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "processed_inputs = tokenise_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da4dd24-e74e-4205-9adb-aaec6f86c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char to num\n",
    "char = sorted(list(set(processed_inputs)))\n",
    "ch2num = dict((c,i) for i, c in enumerate(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eebe25fb-c908-456e-a293-b8a0ae372b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters 255569\n",
      "vocab 43\n"
     ]
    }
   ],
   "source": [
    "# Cheking ch2num\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(char)\n",
    "print(\"characters\", input_len)\n",
    "print(\"vocab\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d08b2b-6152-4dfa-a977-4bce4cfe6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq len\n",
    "seq_len = 100\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45fc3c3f-6c59-4b50-a5bf-554af7fdad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tortal patterns :  255469\n"
     ]
    }
   ],
   "source": [
    "# Looping in seq\n",
    "for i in range(0, input_len - seq_len, 1):\n",
    "    in_ = processed_inputs[i:i + seq_len]\n",
    "    out = processed_inputs[i + seq_len]\n",
    "    x.append([ch2num[char] for char in in_])\n",
    "    y.append(ch2num[out])\n",
    "\n",
    "n_patterns = len(x)\n",
    "print(\"Tortal patterns : \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5462feca-b32d-4c35-9321-0111f269a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input seq to np array\n",
    "X = np.reshape(x, (n_patterns, seq_len, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c047abe8-df1c-4216-b0a5-3cfe14209e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "Y = np_utils.to_categorical(y, num_classes=vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7fa58fc-1188-4ffa-81d2-4ba97de32c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e616190f-be2f-4a35-b5e8-05f5c0dfe02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb958299-1976-471a-a639-073624383cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving weights\n",
    "filepath = \"best_model.h5\"\n",
    "chekpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [chekpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e33807d6-19c7-466f-9c36-fa23d9ab4ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "998/998 [==============================] - ETA: 0s - loss: 2.8709\n",
      "Epoch 1: loss improved from inf to 2.87091, saving model to best_model.h5\n",
      "998/998 [==============================] - 3192s 3s/step - loss: 2.8709\n",
      "Epoch 2/4\n",
      "998/998 [==============================] - ETA: 0s - loss: 2.5693\n",
      "Epoch 2: loss improved from 2.87091 to 2.56933, saving model to best_model.h5\n",
      "998/998 [==============================] - 3422s 3s/step - loss: 2.5693\n",
      "Epoch 3/4\n",
      "998/998 [==============================] - ETA: 0s - loss: 2.3964\n",
      "Epoch 3: loss improved from 2.56933 to 2.39636, saving model to best_model.h5\n",
      "998/998 [==============================] - 3503s 4s/step - loss: 2.3964\n",
      "Epoch 4/4\n",
      "998/998 [==============================] - ETA: 0s - loss: 2.2594\n",
      "Epoch 4: loss improved from 2.39636 to 2.25936, saving model to best_model.h5\n",
      "998/998 [==============================] - 3267s 3s/step - loss: 2.2594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20505d12d30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and train model\n",
    "model.fit(X, Y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcc7e893-0cb3-4495-a9ec-8b889398f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the model \n",
    "filename = \"best_model.h5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d969b97-7d66-4cc4-aac6-e2fb848858c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output back into chars\n",
    "num2ch = dict((i,c) for i, c in enumerate(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb6490c7-cca9-43ef-bb98-cf0f5e4f2e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed:\n",
      "\" ions always unsuccessful attributed failure rather inexperience mistake want skill fidelity instruct \"\n"
     ]
    }
   ],
   "source": [
    "# Random sdeed to help generate\n",
    "start = np.random.randint(0, len(x) - 1)\n",
    "pattern = x[start]\n",
    "print(\"Random seed:\")\n",
    "print(\"\\\"\", ''.join([num2ch[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc0ebdd-e1bb-4698-8ed7-9648da600cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate characters\n",
    "generated_text = []\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = num2ch[index]\n",
    "    generated_text.append(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4994c18d-e806-49ea-96c4-8c0461ac4cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "ion seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare \n"
     ]
    }
   ],
   "source": [
    "# Output generated text\n",
    "print(\"Generated Text:\")\n",
    "print(''.join(generated_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
